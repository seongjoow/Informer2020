{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if not 'Informer2020' in sys.path:\n",
    "    # print(sys.path)\n",
    "    sys.path += ['Informer2020']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments: Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tools import dotdict\n",
    "from exp.exp_informer import Exp_Informer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dotdict()\n",
    "\n",
    "args.model = 'informer' # model of experiment, options: [informer, informerstack, informerlight(TBD)]\n",
    "\n",
    "args.data = 'custom' # data\n",
    "args.root_path = './data/wowsan/' # root path of data file\n",
    "args.data_path = 'merged_df.csv' # data file\n",
    "args.features = 'M' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n",
    "args.target = 'Throughput_0' # target feature in S or MS task\n",
    "args.freq = 's' # freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h\n",
    "args.checkpoints = './informer_checkpoints' # location of model checkpoints\n",
    "\n",
    "args.seq_len = 96 # input sequence length of Informer encoder\n",
    "args.label_len = 48 # start token length of Informer decoder\n",
    "args.pred_len = 24 # prediction sequence length\n",
    "# Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n",
    "\n",
    "args.enc_in = 28 # encoder input size\n",
    "args.dec_in = 28 # decoder input size\n",
    "args.c_out = 28 # output size\n",
    "args.factor = 5 # probsparse attn factor\n",
    "args.d_model = 512 # dimension of model\n",
    "args.n_heads = 8 # num of heads\n",
    "args.e_layers = 2 # num of encoder layers\n",
    "args.d_layers = 1 # num of decoder layers\n",
    "args.d_ff = 2048 # dimension of fcn in model\n",
    "args.dropout = 0.05 # dropout\n",
    "args.attn = 'prob' # attention used in encoder, options:[prob, full]\n",
    "args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n",
    "args.activation = 'gelu' # activation\n",
    "args.distil = True # whether to use distilling in encoder\n",
    "args.output_attention = False # whether to output attention in ecoder\n",
    "args.mix = True\n",
    "args.padding = 0\n",
    "# args.freq = 's'\n",
    "\n",
    "args.batch_size = 32 \n",
    "args.learning_rate = 0.00001\n",
    "args.loss = 'mse'\n",
    "args.lradj = 'type1'\n",
    "args.use_amp = False # whether to use automatic mixed precision training\n",
    "\n",
    "args.num_workers = 0\n",
    "args.itr = 1\n",
    "args.train_epochs = 6\n",
    "args.patience = 3\n",
    "args.des = 'exp'\n",
    "\n",
    "args.use_gpu = True if torch.cuda.is_available() else False\n",
    "args.gpu = 0\n",
    "\n",
    "args.use_multi_gpu = False\n",
    "args.devices = '0,1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    args.devices = args.devices.replace(' ','')\n",
    "    device_ids = args.devices.split(',')\n",
    "    args.device_ids = [int(id_) for id_ in device_ids]\n",
    "    args.gpu = args.device_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set augments by using data name\n",
    "data_parser = {\n",
    "    'ETTh1':{'data':'ETTh1.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
    "    'ETTh2':{'data':'ETTh2.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
    "    'ETTm1':{'data':'ETTm1.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
    "    'ETTm2':{'data':'ETTm2.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
    "}\n",
    "if args.data in data_parser.keys():\n",
    "    data_info = data_parser[args.data]\n",
    "    args.data_path = data_info['data']\n",
    "    args.target = data_info['T']\n",
    "    args.enc_in, args.dec_in, args.c_out = data_info[args.features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.detail_freq = args.freq\n",
    "args.freq = args.freq[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "{'model': 'informer', 'data': 'custom', 'root_path': './data/wowsan/', 'data_path': 'merged_df.csv', 'features': 'M', 'target': 'Throughput_0', 'freq': 's', 'checkpoints': './informer_checkpoints', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 28, 'dec_in': 28, 'c_out': 28, 'factor': 5, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'batch_size': 32, 'learning_rate': 1e-05, 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 8, 'patience': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'detail_freq': 's'}\n"
     ]
    }
   ],
   "source": [
    "print('Args in experiment:')\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exp = Exp_Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 2367\n",
      "val 333\n",
      "test 687\n",
      "Epoch: 1 cost time: 6.278713941574097\n",
      "Epoch: 1, Steps: 73 | Train Loss: nan Vali Loss: nan Test Loss: nan\n",
      "Validation loss decreased (inf --> nan).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "Epoch: 2 cost time: 4.581550121307373\n",
      "Epoch: 2, Steps: 73 | Train Loss: nan Vali Loss: nan Test Loss: nan\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 5e-06\n",
      "Epoch: 3 cost time: 4.608189582824707\n",
      "Epoch: 3, Steps: 73 | Train Loss: nan Vali Loss: nan Test Loss: nan\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 2.5e-06\n",
      "Epoch: 4 cost time: 4.638493061065674\n",
      "Epoch: 4, Steps: 73 | Train Loss: nan Vali Loss: nan Test Loss: nan\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 1.25e-06\n",
      "Epoch: 5 cost time: 4.67705225944519\n",
      "Epoch: 5, Steps: 73 | Train Loss: nan Vali Loss: nan Test Loss: nan\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 6.25e-07\n",
      "Epoch: 6 cost time: 4.64074182510376\n",
      "Epoch: 6, Steps: 73 | Train Loss: nan Vali Loss: nan Test Loss: nan\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 3.125e-07\n",
      "Epoch: 7 cost time: 4.611555576324463\n",
      "Epoch: 7, Steps: 73 | Train Loss: nan Vali Loss: nan Test Loss: nan\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 1.5625e-07\n",
      "Epoch: 8 cost time: 4.562539577484131\n",
      "Epoch: 8, Steps: 73 | Train Loss: nan Vali Loss: nan Test Loss: nan\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 7.8125e-08\n",
      ">>>>>>>testing : informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 687\n",
      "test shape: (21, 32, 24, 28) (21, 32, 24, 28)\n",
      "test shape: (672, 24, 28) (672, 24, 28)\n",
      "mse:nan, mae:nan\n"
     ]
    }
   ],
   "source": [
    "for ii in range(args.itr):\n",
    "    # setting record of experiments\n",
    "    setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n",
    "                args.seq_len, args.label_len, args.pred_len,\n",
    "                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, ii)\n",
    "\n",
    "    # set experiments\n",
    "    exp = Exp(args)\n",
    "    \n",
    "    # train\n",
    "    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "    exp.train(setting)\n",
    "    \n",
    "    # test\n",
    "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "    exp.test(setting)\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data_loader import Dataset_Custom\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.root_path = './data/wowsan/' # root path of data file\n",
    "args.data_path = 'merged_df.csv' # data file\n",
    "\n",
    "df = pd.read_csv(os.path.join(args.root_path, args.data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>HopCount</th>\n",
       "      <th>Timestamp_0</th>\n",
       "      <th>Cpu_0</th>\n",
       "      <th>Memory_0</th>\n",
       "      <th>InterArrivalTime_0</th>\n",
       "      <th>QueueLength_0</th>\n",
       "      <th>QueueTime_0</th>\n",
       "      <th>ServiceTime_0</th>\n",
       "      <th>ResponseTime_0</th>\n",
       "      <th>...</th>\n",
       "      <th>Throughput_1</th>\n",
       "      <th>Timestamp_2</th>\n",
       "      <th>Cpu_2</th>\n",
       "      <th>Memory_2</th>\n",
       "      <th>InterArrivalTime_2</th>\n",
       "      <th>QueueLength_2</th>\n",
       "      <th>QueueTime_2</th>\n",
       "      <th>ServiceTime_2</th>\n",
       "      <th>ResponseTime_2</th>\n",
       "      <th>Throughput_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2024-06-18 17:30:49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.828325</td>\n",
       "      <td>20930560.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2024-06-18 17:30:50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.531350</td>\n",
       "      <td>23437312.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2024-06-18 17:30:51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.558337</td>\n",
       "      <td>23568384.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2024-06-18 17:30:52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.189702</td>\n",
       "      <td>23588864.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2024-06-18 17:30:53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.443920</td>\n",
       "      <td>23588864.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  HopCount  Timestamp_0      Cpu_0    Memory_0  \\\n",
       "0  2024-06-18 17:30:49       0.0          0.0  29.828325  20930560.0   \n",
       "1  2024-06-18 17:30:50       0.0          0.0  40.531350  23437312.0   \n",
       "2  2024-06-18 17:30:51       0.0          0.0  42.558337  23568384.0   \n",
       "3  2024-06-18 17:30:52       0.0          0.0  45.189702  23588864.0   \n",
       "4  2024-06-18 17:30:53       0.0          0.0  46.443920  23588864.0   \n",
       "\n",
       "   InterArrivalTime_0  QueueLength_0  QueueTime_0  ServiceTime_0  \\\n",
       "0                 0.0            0.0          0.0            0.0   \n",
       "1                 0.0            0.0          0.0            0.0   \n",
       "2                 0.0            0.0          0.0            0.0   \n",
       "3                 0.0            0.0          0.0            0.0   \n",
       "4                 0.0            0.0          0.0            0.0   \n",
       "\n",
       "   ResponseTime_0  ...  Throughput_1  Timestamp_2  Cpu_2  Memory_2  \\\n",
       "0             0.0  ...           0.0          0.0    0.0       0.0   \n",
       "1             0.0  ...           0.0          0.0    0.0       0.0   \n",
       "2             0.0  ...           0.0          0.0    0.0       0.0   \n",
       "3             0.0  ...           0.0          0.0    0.0       0.0   \n",
       "4             0.0  ...           0.0          0.0    0.0       0.0   \n",
       "\n",
       "   InterArrivalTime_2  QueueLength_2  QueueTime_2  ServiceTime_2  \\\n",
       "0                 0.0            0.0          0.0            0.0   \n",
       "1                 0.0            0.0          0.0            0.0   \n",
       "2                 0.0            0.0          0.0            0.0   \n",
       "3                 0.0            0.0          0.0            0.0   \n",
       "4                 0.0            0.0          0.0            0.0   \n",
       "\n",
       "   ResponseTime_2  Throughput_2  \n",
       "0             0.0           0.0  \n",
       "1             0.0           0.0  \n",
       "2             0.0           0.0  \n",
       "3             0.0           0.0  \n",
       "4             0.0           0.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.target = 'Throughput_0'\n",
    "args.freq = 's'\n",
    "\n",
    "Data = Dataset_Custom\n",
    "timeenc = 0 if args.embed!='timeF' else 1\n",
    "flag = 'test'; shuffle_flag = False; drop_last = True; batch_size = 1\n",
    "\n",
    "data_set = Data(\n",
    "    root_path=args.root_path,\n",
    "    data_path=args.data_path,\n",
    "    flag=flag,\n",
    "    size=[args.seq_len, args.label_len, args.pred_len],\n",
    "    features=args.features,\n",
    "    timeenc=timeenc,\n",
    "    target=args.target, # HULL here\n",
    "    freq=args.freq # 'h': hourly, 't':minutely\n",
    ")\n",
    "data_loader = DataLoader(\n",
    "    data_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=shuffle_flag,\n",
    "    num_workers=args.num_workers,\n",
    "    drop_last=drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x,batch_y,batch_x_mark,batch_y_mark = data_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exp = Exp_Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 2367\n",
      "val 333\n",
      "test 687\n",
      "Epoch: 1 cost time: 4.911206483840942\n",
      "Epoch: 1, Steps: 73 | Train Loss: nan Vali Loss: nan Test Loss: nan\n",
      "Validation loss decreased (inf --> nan).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "Epoch: 2 cost time: 4.633054494857788\n",
      "Epoch: 2, Steps: 73 | Train Loss: nan Vali Loss: nan Test Loss: nan\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 5e-06\n",
      "Epoch: 3 cost time: 4.595931053161621\n",
      "Epoch: 3, Steps: 73 | Train Loss: nan Vali Loss: nan Test Loss: nan\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 2.5e-06\n",
      "Epoch: 4 cost time: 4.610515594482422\n",
      "Epoch: 4, Steps: 73 | Train Loss: nan Vali Loss: nan Test Loss: nan\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 1.25e-06\n",
      "Epoch: 5 cost time: 4.589077472686768\n",
      "Epoch: 5, Steps: 73 | Train Loss: nan Vali Loss: nan Test Loss: nan\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 6.25e-07\n",
      "Epoch: 6 cost time: 4.564278841018677\n",
      "Epoch: 6, Steps: 73 | Train Loss: nan Vali Loss: nan Test Loss: nan\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 3.125e-07\n",
      "Epoch: 7 cost time: 4.595251083374023\n",
      "Epoch: 7, Steps: 73 | Train Loss: nan Vali Loss: nan Test Loss: nan\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 1.5625e-07\n",
      "Epoch: 8 cost time: 4.484345197677612\n",
      "Epoch: 8, Steps: 73 | Train Loss: nan Vali Loss: nan Test Loss: nan\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 7.8125e-08\n",
      ">>>>>>>testing : informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 687\n",
      "test shape: (21, 32, 24, 28) (21, 32, 24, 28)\n",
      "test shape: (672, 24, 28) (672, 24, 28)\n",
      "mse:nan, mae:nan\n"
     ]
    }
   ],
   "source": [
    "for ii in range(args.itr):\n",
    "    # setting record of experiments\n",
    "    setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n",
    "                args.seq_len, args.label_len, args.pred_len,\n",
    "                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, ii)\n",
    "\n",
    "    # set experiments\n",
    "    exp = Exp(args)\n",
    "    \n",
    "    # train\n",
    "    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "    exp.train(setting)\n",
    "    \n",
    "    # test\n",
    "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "    exp.test(setting)\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "informer2020",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
